{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prosy/Augmented-Worlds/blob/main/Copy_of_Mazda_RAG_Orchestration_MVP_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609cf30a",
      "metadata": {
        "id": "609cf30a"
      },
      "source": [
        "# Mazda Owner's Manual RAG — **MVP Orchestration Notebook (v2)**\n",
        "\n",
        "**Goal:** Keep Mazda-specific structure, but include a tiny in-notebook BM25 test and clear comments for swapping to FAISS/ColBERT.\n",
        "Outputs export to `/app/` so your live app can use them immediately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe1f8cc",
      "metadata": {
        "id": "3fe1f8cc"
      },
      "source": [
        "## 0) Setup (install if needed)\n",
        "\n",
        "Notebook is dependency-light. You can run as-is for the demo (BM25-ish). If you want FAISS/ColBERT, install and wire in the optional cells later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "976b6eae",
      "metadata": {
        "id": "976b6eae"
      },
      "source": [
        "## 1) Config paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json, csv, re, time, shutil, math\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r6k5UnuTsqY0"
      },
      "id": "r6k5UnuTsqY0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9db6122c",
      "metadata": {
        "id": "9db6122c"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Set project output root explicitly\n",
        "WORK_ROOT = Path(\"/Users/blackcat/MyDrive/AugWorlds/Mazda_PDFs\")\n",
        "\n",
        "# Define subdirectories inside Mazda_PDFs for pipeline outputs\n",
        "PARSED_DIR = WORK_ROOT / \"parsed\"\n",
        "ENRICHED_DIR = WORK_ROOT / \"enriched\"\n",
        "INDEX_DIR = WORK_ROOT / \"index\"\n",
        "APP_DIR = WORK_ROOT / \"app\"  # app configs also stored here\n",
        "\n",
        "# Mazda-specific input PDF\n",
        "INPUT_PDF = WORK_ROOT / \"2024-cx-50-owners-manual.pdf\"  # Mazda PDF lives in same folder\n",
        "MODEL_YEAR = \"2024\"  # for configs if needed\n",
        "\n",
        "# Config files used by the live app\n",
        "SYNONYMS_CSV = APP_DIR / \"config\" / \"synonyms.csv\"\n",
        "ANS_PLANS_JSON = APP_DIR / \"config\" / \"answer_plans.json\"\n",
        "RETRIEVAL_CFG = APP_DIR / \"config\" / \"retrieval_config.yaml\"\n",
        "\n",
        "# Ensure output directories exist\n",
        "for d in [PARSED_DIR, ENRICHED_DIR, INDEX_DIR, APP_DIR, APP_DIR / \"config\"]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"WORK_ROOT:\", WORK_ROOT)\n",
        "print(\"INPUT_PDF:\", INPUT_PDF)\n",
        "\n",
        "if INPUT_PDF.is_file():\n",
        "    print(f\"✅ Found Mazda PDF: {INPUT_PDF}\")\n",
        "else:\n",
        "    print(f\"❌ PDF not found or path incorrect: {INPUT_PDF}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a245a2",
      "metadata": {
        "id": "e0a245a2"
      },
      "source": [
        "## 2) Parsing: chunk pages + harvest TOC lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112e5084",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "112e5084",
        "outputId": "1e403322-5e11-4181-e377-9bea11338aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed → /Users/blackcat/MyDrive/AugWorlds/Mazda_PDFs/parsed/sections_2024.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Replace with your real parser (PyMuPDF/Tika). Demo JSONL for structure.\n",
        "SECTIONS_JSONL = PARSED_DIR / f\"sections_{MODEL_YEAR}.jsonl\"\n",
        "if not SECTIONS_JSONL.exists():\n",
        "    demo_sections = [\n",
        "        {\"manual_ref\": \"1-1\", \"title\": \"Introduction\", \"text\": \"Welcome to your Mazda owner's manual.\"},\n",
        "        {\"manual_ref\": \"2-14\", \"title\": \"TPMS\", \"text\": \"TPMS monitors tire pressure and warns if it is low.\"},\n",
        "        {\"manual_ref\": \"3-2\", \"title\": \"Engine Oil\", \"text\": \"Use 0W-20. Check level regularly.\"},\n",
        "    ]\n",
        "    with open(SECTIONS_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, row in enumerate(demo_sections):\n",
        "            # Explicitly add _id starting from 0 for demo data consistency\n",
        "            row[\"_id\"] = i\n",
        "            f.write(json.dumps(row) + \"\\n\")\n",
        "print(\"Parsed →\", SECTIONS_JSONL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc90bbc",
      "metadata": {
        "id": "1cc90bbc"
      },
      "source": [
        "## 3) Enrichment: fill `manual_ref` for Top-20 plans (per year/manual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9269cc29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9269cc29",
        "outputId": "4e4428be-0233-4136-ea12-7198a9be4d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enriched → /Users/blackcat/MyDrive/AugWorlds/Mazda_PDFs/enriched/sections_2024.enriched.jsonl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def load_synonyms(path=SYNONYMS_CSV):\n",
        "    norm = {}\n",
        "    if path.exists():\n",
        "        import csv\n",
        "        with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
        "            for row in csv.DictReader(f):\n",
        "                canonical = row[\"canonical\"].strip()\n",
        "                for alias in row[\"alias_list\"].split(\"|\"):\n",
        "                    norm[alias.strip().lower()] = canonical.lower()\n",
        "    return norm\n",
        "\n",
        "def normalize_text(text: str, norm_map: dict):\n",
        "    out = text\n",
        "    for alias, canon in norm_map.items():\n",
        "        out = re.sub(rf\"\\b{re.escape(alias)}\\b\", canon, out, flags=re.IGNORECASE)\n",
        "    return out\n",
        "\n",
        "norm_map = load_synonyms()\n",
        "\n",
        "ENRICHED_JSONL = ENRICHED_DIR / f\"sections_{MODEL_YEAR}.enriched.jsonl\"\n",
        "with open(SECTIONS_JSONL, \"r\", encoding=\"utf-8\") as fin, open(ENRICHED_JSONL, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for line in fin:\n",
        "        rec = json.loads(line)\n",
        "        rec[\"text_norm\"] = normalize_text(rec[\"text\"], norm_map)\n",
        "        rec[\"metadata\"] = {\"source\": \"mazda_demo\", \"model_year\": MODEL_YEAR, \"ts\": int(time.time())}\n",
        "        fout.write(json.dumps(rec) + \"\\n\")\n",
        "\n",
        "print(\"Enriched →\", ENRICHED_JSONL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6159f338",
      "metadata": {
        "id": "6159f338"
      },
      "source": [
        "## 4) Indexing: build lightweight retrieval artifacts (BM25-ish demo)\n",
        "\n",
        "*This cell provides an in-notebook BM25-like index so the notebook works out-of-the-box.*\n",
        "\n",
        "**Swap to FAISS/ColBERT**:\n",
        "- FAISS: create vectors for `text_norm`, save `faiss.index` + `docs.jsonl` under `app/index/`.\n",
        "- ColBERT: run your existing CLI to build an index and then point to it via `app/config/retrieval_config.yaml`.\n",
        "Keep the *calling interface* below so your app code remains unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d00ee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63d00ee5",
        "outputId": "17b139aa-78cc-4687-e707-9acaa4fcce2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index written → /Users/blackcat/MyDrive/AugWorlds/Mazda_PDFs/index/bm25_index_2024.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "INDEX_JSON = INDEX_DIR / f\"bm25_index_{MODEL_YEAR}.json\"\n",
        "DOCS_JSON = INDEX_DIR / f\"docs_{MODEL_YEAR}.jsonl\"\n",
        "\n",
        "# Load docs\n",
        "docs = []\n",
        "with open(ENRICHED_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        rec = json.loads(line)\n",
        "        rec[\"_id\"] = i\n",
        "        docs.append(rec)\n",
        "\n",
        "def tokenize(s):\n",
        "    import re\n",
        "    return re.findall(r\"[a-z0-9_]+\", s.lower())\n",
        "\n",
        "N = len(docs)\n",
        "df = defaultdict(int)\n",
        "postings = defaultdict(list)   # term -> list of (doc_id, tf)\n",
        "doc_len = {}\n",
        "\n",
        "for d in docs:\n",
        "    tokens = tokenize(d[\"text_norm\"])\n",
        "    doc_len[d[\"_id\"]] = len(tokens)\n",
        "    tf = defaultdict(int)\n",
        "    for t in tokens:\n",
        "        tf[t] += 1\n",
        "    for t, c in tf.items():\n",
        "        df[t] += 1\n",
        "        postings[t].append((d[\"_id\"], c))\n",
        "\n",
        "index_obj = {\n",
        "    \"N\": N,\n",
        "    \"df\": dict(df),\n",
        "    \"doc_len\": {int(k): int(v) for k, v in doc_len.items()},\n",
        "    \"postings\": {t: [(int(d), int(tf)) for d, tf in lst] for t, lst in postings.items()},\n",
        "}\n",
        "\n",
        "INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
        "with open(DOCS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    for d in docs:\n",
        "        f.write(json.dumps(d) + \"\\n\")\n",
        "with open(INDEX_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(index_obj, f)\n",
        "\n",
        "print(\"Index written →\", INDEX_JSON)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db6e26c6",
      "metadata": {
        "id": "db6e26c6"
      },
      "source": [
        "## 5) Retrieval helper (for your app)\n",
        "\n",
        "BM25-ish search now; swap internals for FAISS/ColBERT and keep the same function signature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c6a349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57c6a349",
        "outputId": "b4d00e36-1203-4c21-fcf5-ae9bd4fe0ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'doc_id': 1, 'score': 0.8626796489204477, 'manual_ref': '2-14', 'title': 'TPMS', 'snippet': 'TPMS monitors tire pressure and warns if it is low.'}]\n"
          ]
        }
      ],
      "source": [
        "def load_index(path=INDEX_JSON):\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "    return json.loads(Path(path).read_text())\n",
        "\n",
        "def bm25_search(query, k=5, k1=1.5, b=0.75):\n",
        "    import math, re, json\n",
        "    idx = load_index()\n",
        "    N = idx[\"N\"]\n",
        "    scores = __import__(\"collections\").defaultdict(float)\n",
        "    tokens = re.findall(r\"[a-z0-9_]+\", query.lower())\n",
        "    avgdl = sum(idx[\"doc_len\"].values())/max(1, N)\n",
        "\n",
        "    # Load docs into a dictionary keyed by their _id\n",
        "    doc_map = {}\n",
        "    with open(DOCS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            doc = json.loads(line)\n",
        "            doc_map[doc[\"_id\"]] = doc\n",
        "\n",
        "    for t in tokens:\n",
        "        df = idx[\"df\"].get(t, 0)\n",
        "        if df == 0:\n",
        "            continue\n",
        "        idf = math.log((N - df + 0.5) / (df + 0.5) + 1)\n",
        "        for doc_id, tf in idx[\"postings\"].get(t, []):\n",
        "            # Retrieve doc length from the doc_map using the correct doc_id\n",
        "            dl = len(re.findall(r\"[a-z0-9_]+\", doc_map[doc_id][\"text_norm\"].lower()))\n",
        "            denom = tf + k1*(1 - b + b*dl/avgdl)\n",
        "            scores[doc_id] += idf * (tf*(k1+1))/denom\n",
        "    top = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    # map to docs\n",
        "    results = []\n",
        "    for doc_id, score in top:\n",
        "        d = doc_map[doc_id]\n",
        "        results.append({\n",
        "            \"doc_id\": doc_id, \"score\": score,\n",
        "            \"manual_ref\": d[\"manual_ref\"], \"title\": d[\"title\"], \"snippet\": d[\"text_norm\"][:240]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "print(bm25_search(\"tpms warning light\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d768cab",
      "metadata": {
        "id": "3d768cab"
      },
      "source": [
        "## 6) One-click: Copy artifacts into `/app/` layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faaf031b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faaf031b",
        "outputId": "192d8389-d681-454b-c91d-ce0c6a4fcced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export complete → /Users/blackcat/MyDrive/AugWorlds/Mazda_PDFs/app\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def export_to_app():\n",
        "    targets = [\n",
        "        (PARSED_DIR, APP_DIR / \"data\" / \"parsed\"),\n",
        "        (ENRICHED_DIR, APP_DIR / \"data\" / \"enriched\"),\n",
        "        (INDEX_DIR, APP_DIR / \"index\"),\n",
        "    ]\n",
        "    for src, dst in targets:\n",
        "        dst.mkdir(parents=True, exist_ok=True)\n",
        "        for p in src.glob(\"**/*\"):\n",
        "            if p.is_file():\n",
        "                rel = p.relative_to(src)\n",
        "                (dst / rel).parent.mkdir(parents=True, exist_ok=True)\n",
        "                shutil.copy2(p, dst / rel)\n",
        "    print(\"Export complete →\", APP_DIR.resolve())\n",
        "\n",
        "export_to_app()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}